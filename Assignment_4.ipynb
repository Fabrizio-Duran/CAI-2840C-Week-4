{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5ABrRjJB6u5W6KSLzOLk3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fabrizio-Duran/CAI-2840C-Week-4/blob/main/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1: Video I/O Application**\n",
        "\n",
        "Requirements:\n",
        "\n",
        "Input: Use any video file of your choice (or create one, e.g., using your webcam or a synthetic video clip that is less than 1 minute long).\n",
        "Processing: Implement a simple transformation on each frame (this can be as basic as converting to grayscale, overlaying text, or drawing shapes).\n",
        "Output: Write the processed frames to a new video file.\n",
        "Instructions:\n",
        "\n",
        "Reading the Video:\n",
        "Use cv2.VideoCapture to open the video file.\n",
        "Loop through each frame and perform your processing.\n",
        "Processing the Frames:\n",
        "Apply your chosen transformation (for example, add a timestamp overlay or convert to grayscale).\n",
        "Writing the Video:\n",
        "Use cv2.VideoWriter to create an output video file.\n",
        "Write the processed frames to this file.\n",
        "Hint: Ensure your output video settings (frame size, codec, and frame rate) match the input video."
      ],
      "metadata": {
        "id": "snARoMr3Ap7u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnRCap81A3pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2: Motion Detection Application with Foreground Mass and Erosion**\n",
        "\n",
        "Requirements:\n",
        "\n",
        "Input: Use a video clip (less than one minute long) that shows some movement.\n",
        "Processing:\n",
        "Create a background model from the initial frames.\n",
        "Compute the foreground mass by taking the difference between the current frame and the background model.\n",
        "Apply erosion to the foreground mask to remove noise (explain how erosion removes small, isolated noise pixels).\n",
        "Output: Annotate the frames (e.g., draw bounding boxes around detected motion areas) and write the output to a new video file.\n",
        "Instructions:\n",
        "\n",
        "Background Modeling & Foreground Mass:\n",
        "Applying Erosion:\n",
        "Annotation and Video Output:\n",
        "Draw bounding rectangles (or other markers) around the regions of motion detected in the eroded foreground mask.\n",
        "Write the annotated frames to a new output video.\n",
        "Bonus: You can include intermediate visualizations (e.g., display the raw foreground mask vs. the eroded mask) to show the effect of erosion."
      ],
      "metadata": {
        "id": "xh1m77z0AqG-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvRQw79gA42m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3: Contour Detection Application**\n",
        "\n",
        "Requirements:\n",
        "\n",
        "Input: Use an image that contains distinct shapes (or create one with simple geometric shapes).\n",
        "Processing:\n",
        "Convert the image to grayscale and threshold it to create a binary image.\n",
        "Use cv2.findContours to detect the contours.\n",
        "Use cv2.drawContours to overlay the detected contours on the original image.\n",
        "Output: Display the resulting image with contours drawn.\n",
        "Bonus: Extend your code to process a video stream frame-by-frame, drawing contours on each frame.\n",
        "Instructions:\n",
        "\n",
        "Image Preprocessing:\n",
        "Load the image and convert it to grayscale.\n",
        "Apply a binary threshold to segment the shapes.\n",
        "Contour Detection:\n",
        "Use cv2.findContours with appropriate retrieval and approximation modes.\n",
        "Explain the output: a list of contours and (optionally) a hierarchy that indicates relationships between contours.\n",
        "Drawing the Contours:\n",
        "Use cv2.drawContours to overlay the detected contours onto the image.\n",
        "Display the final image.\n",
        "(Bonus) Video Contour Detection:\n",
        "Modify your code from Part 1 to process a video.\n",
        "For each frame, detect contours and draw them before writing the frame to an output video file.\n",
        "Hint: Choose a short video clip (under one minute) to ensure quick processing and review.\n",
        "\n"
      ],
      "metadata": {
        "id": "QcZ9RbqVAqPg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TcU-Stc_A51X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}